---
layout: post
title:  Java Web 集群的简单实现
date:   2017-7-19 19:56:25 +0800
categories: Java Web
tag: 
---

* content
{:toc}


没有使用nigix  而是用的阿里云的负载均衡 , 没有使用oss存储 , Session共享方案 tomcat + redis  

文件共享使用的是 nfs + rpcbind  在linux通过挂载进行共享  并配置tomcat的虚拟目录进行文件的读写操作

### 首先要解决的是session共享

1. 找到redis,安装redis,网上教程一大堆,就不再详细说明了,如果需要远程访问,则需要将bind 127.0.0.1  换成 0.0.0.0 则可以远程访问,记得加上密码 
2. 将每个服务器的tomcat中的 /conf/content.xml


```
<Valve className="com.radiadesign.catalina.session.RedisSessionHandlerValve" />    
<Manager className="com.radiadesign.catalina.session.RedisSessionManager"    
         host="106.14.1.102"
         port="6379"
         database="1"
         password="water-wj-123!@#"
         maxInactiveInterval="60" /> 
<!-- host:redis服务器的Ip地址 -->
<!-- port:redis使用的端口 -->
<!-- database:使用redis的哪个数据库 1 代表第二个数据库 -->
<!-- password:redis数据库的认证密码 -->
<!-- maxInactiveInterval:session的过期时间,但是会以web.xml为准 -->
```


[所需要的jar包,共4个,已经打包,点击下载!!! 并且把这些文件放在tomcat的lib文件夹下](http://note.youdao.com/yws/api/personal/file/6ABC8358E98042D784449326D52BF12E?method=download&shareKey=cb1a1d085e83e415c1836e890181bb91)

### 使用nfs解决文件的共享问题

> center os 为 7.0 以上版本   

1. 查看系统是否已安装NFS,如果没有则进行安装操作  

```
rpm -qa | grep rpcbind  
rpm -qa | grep nfs
```


2. 在nfs服务器上安装 rpcbind  和  nfs 两个软件  

```
yum -y install nfs-utils rpcbind
```


3. 设置本地要共享的目录,我这里设置的根节点下的data文件夹 , 并设置权限

```
mkdir -p /data/  
chmod 777 /data/
```


4. 配置共享服务器 : 配置文件在 /etc/exports   
直接使用vi /etc/exports 有就编辑没有有新建
内容 : /data/ 192.168.2.0/24(rw,no_root_squash,no_all_squash,sync)  
个人理解是将/data/这个文件夹共享出来,共享出来的Ip地址段是 192.168.0.1-24这个ip段的客户端可以使用   

> 常见的参数则有：  
> 
> 参数值内容说明  
> 
> rw　　ro    该目录分享的权限是可擦写 (read-write) 或只读 (read-only)，但最终能不能读写，还是与文件系统的 rwx 及身份有关。  
> 
> sync　　async    sync 代表数据会同步写入到内存与硬盘中，async 则代表数据会先暂存于内存当中，而非直接写入硬盘！
> 
> no_root_squash　　root_squash    客户端使用 NFS 文件系统的账号若为 root 时，系统该如何判断这个账号的身份？预设的情况下，客户端 root 的身份会由 root_squash 的设定压缩成 nfsnobody， 如此对服务器的系统会较有保障。但如果你想要开放客户端使用 root 身份来操作服务器的文件系统，那么这里就得要开 no_root_squash 才行！
> all_squash    不论登入 NFS 的使用者身份为何， 他的身份都会被压缩成为匿名用户，通常也就是 nobody(nfsnobody) 啦！
>
> anonuid　　anongid    anon 意指 anonymous (匿名者) 前面关于 *_squash 提到的匿名用户的 UID 设定值，通常为 nobody(nfsnobody)，但是你可以自行设定这个 UID 的值！当然，这个 UID 必需要存在于你的 /etc/passwd 当中！ anonuid 指的是 UID 而 anongid 则是群组的 GID 啰。 

5. 配置生效  

```
exportfs -r
```
6. 先为rpcbind和nfs做开机启动：

```
systemctl enable rpcbind.service
systemctl enable nfs.service
```

7. 然后分别启动rpcbind和nfs服务：

```
systemctl start rpcbind.service
systemctl start nfs-server.service
```
8. 确认NFS服务器启动成功： 

```
rpcinfo -p
```
9. 检查 NFS 服务器是否挂载我们想共享的目录 /data：

```
exportfs
#可以查看到已经ok
/data           192.168.0.10
/data           192.168.0.11
```

### 在从机上安装NFS 客户端

1. 安裝nfs，同上，然后启动rpcbind服务

```
systemctl enable rpcbind.service
```
2. 启动rpcbind服务：  **注意：客户端不需要启动nfs服务**

```
systemctl start rpcbind.service
```
3. 检查 NFS 服务器端是否有目录共享：

```
showmount -e nfs服务器的IP
```
4. 在从机上使用 mount 挂载服务器端的目录/data到客户端某个目录下：


```
mkdir /data
mount -t nfs4 nfs服务器IP:/data    /data
df -h 查看是否挂载成功
```
5. 想在客户机上实现开机挂载，则需要编辑/etc/fstab：

```
vi /etc/fstab
# 加上
nfs服务器IP:/   /data  nfs4 ro,hard,intr,proto=tcp,port=2049,noauto 0 0
```

6. (如果需要修改配置文件)重新读取NFS配置文件： 

```
exportfs -rv
```



### 经过上述步骤的到一个,共享目录,接下来我们将此文件夹配置成为 tomcat 的虚拟文件夹

配置如下 


```
<Host name="localhost"  appBase="webapps" unpackWARs="true" autoDeploy="true">

    <Alias>www.qhwj123.com</Alias>
    
    <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt"  pattern="%h %l %u %t &quot;%r&quot; %s %b" />  
    
    <Context path="/files" docBase="/data/files" debug="0" reloadable="true"></Context>  
    
    <Context path="" docBase="/usr/local/apache-tomcat-8.0.35/webapps/HxFramework_htsl_mall" debug="0" reloadable="true"></Context>  

</Host>
```
节点解释:  

alias 网站域名  

第一个 context 节点  虚拟目录,如果有请求是以/files请求,则 tomcat 会到/data/files文件夹中处理这个请求

第二个 content 节点 目的为了取消访问网站时候加上项目名称



### 此外还需要做出的一些调整.

1. 以前上传的时候是直接获取网站根目录这样的方式,的到一个绝对路径,进行网站文件上传,这个时候我们从共享目录中读取文件了,那么我们在上传的时候也要把路径改为这个虚拟路径(共享路径)
2. 如果使用ueditor的话,也要将路径配置到对应的 虚拟路径(共享路径) 


做完以上步骤,这个web才算是完成了集群的一些配置,算是能正常访问了吧!

